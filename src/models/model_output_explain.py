

# 关于模型输出的可解释性研究


'''
# 这份代码实际上跟本项目没啥关系， 但是你如果感兴趣的话，可以看看

# 本代码基于论文《LANGUAGE MODELS REPRESENT SPACE AND TIME》编写，使用可视化的方法来分析模型输出中潜藏的含义

# 本论文的作者试图证明，大模型是真的听得懂人话的，而不仅仅是 next-token 预测的结果。

'''
