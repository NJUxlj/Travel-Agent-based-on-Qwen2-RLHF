# Qwen2.5 ç»§ç»­é¢„è®­ç»ƒæŒ‡å—

## æ¦‚è¿°

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•ä½¿ç”¨å®Œå–„çš„ `CPTTrainer` ç±»å¯¹ Qwen2.5 æ¨¡å‹è¿›è¡Œé«˜æ•ˆçš„ç»§ç»­é¢„è®­ç»ƒã€‚è¯¥å®ç°é›†æˆäº† Muon ä¼˜åŒ–å™¨å’Œå¤šç§æ•ˆç‡ä¼˜åŒ–æŠ€æœ¯ã€‚

## ä¸»è¦ç‰¹æ€§

### ğŸš€ æ•ˆç‡ä¼˜åŒ–
- **Muon ä¼˜åŒ–å™¨**: ç›¸æ¯” AdamW æå‡è¿‘ä¸€å€çš„è®¡ç®—æ•ˆç‡
- **Flash Attention**: åŠ é€Ÿæ³¨æ„åŠ›è®¡ç®—ï¼Œå‡å°‘å†…å­˜ä½¿ç”¨
- **æ¢¯åº¦æ£€æŸ¥ç‚¹**: èŠ‚çœæ˜¾å­˜ï¼Œæ”¯æŒæ›´å¤§æ¨¡å‹
- **æ··åˆç²¾åº¦è®­ç»ƒ**: ä½¿ç”¨ bfloat16 æå‡è®­ç»ƒé€Ÿåº¦
- **æ¢¯åº¦ç´¯ç§¯**: æ”¯æŒå¤§æ‰¹é‡è®­ç»ƒ

### ğŸ“Š é¢„è®­ç»ƒæ•ˆç‡æå‡
- **åŠ¨æ€å­¦ä¹ ç‡è°ƒåº¦**: åŸºäºæ¨¡å‹å‚æ•°é‡è‡ªåŠ¨è°ƒæ•´å­¦ä¹ ç‡
- **æ‰¹é‡å¤§å°ä¼˜åŒ–**: æ ¹æ®æ•°æ®è§„æ¨¡æ™ºèƒ½è°ƒæ•´æ‰¹é‡å¤§å°
- **å†…å­˜ä¼˜åŒ–**: å¤šç§æŠ€æœ¯å‡å°‘æ˜¾å­˜å ç”¨
- **å¹¶è¡Œæ•°æ®åŠ è½½**: å¤šè¿›ç¨‹æ•°æ®é¢„å¤„ç†

## å®‰è£…ä¾èµ–

```bash
# åŸºç¡€ä¾èµ–
pip install -r requirements_cpt.txt

# å®‰è£… Muon ä¼˜åŒ–å™¨ (æ¨è)
pip install muon-optimizer

# å®‰è£… Flash Attention (å¯é€‰ï¼Œéœ€è¦ CUDA)
pip install flash-attn --no-build-isolation
```

## ä½¿ç”¨æ–¹æ³•

### åŸºç¡€ä½¿ç”¨

```python
from src.pretrain.cpt import CPTTrainer, CPTConfig

# åˆ›å»ºé…ç½®
config = CPTConfig(
    model_name_or_path="Qwen/Qwen2.5-7B",
    max_length=2048,
    learning_rate=5e-5,
    num_train_epochs=3,
    per_device_train_batch_size=2,
    gradient_accumulation_steps=8,
    use_muon_optimizer=True,  # ä½¿ç”¨ Muon ä¼˜åŒ–å™¨
    use_flash_attention=True,  # ä½¿ç”¨ Flash Attention
    use_gradient_checkpointing=True,  # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
    use_bf16=True,  # ä½¿ç”¨æ··åˆç²¾åº¦
    output_dir="./cpt_output",
    max_samples=1000
)

# åˆ›å»ºè®­ç»ƒå™¨
trainer = CPTTrainer(config)

# å‡†å¤‡æ•°æ®
train_texts = [
    "ä½ çš„è®­ç»ƒæ–‡æœ¬1",
    "ä½ çš„è®­ç»ƒæ–‡æœ¬2",
    # ... æ›´å¤šæ–‡æœ¬
]

# å¼€å§‹è®­ç»ƒ
final_loss = trainer.train(train_texts)
```

### é«˜çº§é…ç½®

```python
# é’ˆå¯¹å¤§è§„æ¨¡è®­ç»ƒçš„é…ç½®
config = CPTConfig(
    model_name_or_path="Qwen/Qwen2.5-7B",
    max_length=4096,  # æ›´é•¿çš„åºåˆ—é•¿åº¦
    learning_rate=3e-5,  # æ ¹æ®æ¨¡å‹è§„æ¨¡è°ƒæ•´
    num_train_epochs=5,
    per_device_train_batch_size=1,  # å°æ‰¹é‡ä»¥èŠ‚çœæ˜¾å­˜
    gradient_accumulation_steps=16,  # é€šè¿‡æ¢¯åº¦ç´¯ç§¯å®ç°å¤§æ‰¹é‡
    warmup_ratio=0.1,  # æ›´é•¿çš„é¢„çƒ­æœŸ
    weight_decay=0.01,
    max_grad_norm=1.0,
    
    # æ•ˆç‡ä¼˜åŒ–
    use_muon_optimizer=True,
    use_flash_attention=True,
    use_gradient_checkpointing=True,
    use_bf16=True,
    dataloader_num_workers=8,  # æ›´å¤šæ•°æ®åŠ è½½è¿›ç¨‹
    
    # è¾“å‡ºé…ç½®
    output_dir="./large_scale_cpt",
    logging_steps=50,
    save_steps=1000,
    eval_steps=1000,
    save_total_limit=5,
    
    # æ•°æ®é…ç½®
    max_samples=100000  # é™åˆ¶æ•°æ®é‡
)
```

## é…ç½®å‚æ•°è¯´æ˜

### æ¨¡å‹é…ç½®
- `model_name_or_path`: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
- `max_length`: æœ€å¤§åºåˆ—é•¿åº¦
- `trust_remote_code`: æ˜¯å¦ä¿¡ä»»è¿œç¨‹ä»£ç 

### è®­ç»ƒé…ç½®
- `learning_rate`: å­¦ä¹ ç‡ (æ¨è: 3e-5 åˆ° 5e-5)
- `num_train_epochs`: è®­ç»ƒè½®æ•°
- `per_device_train_batch_size`: æ¯è®¾å¤‡æ‰¹é‡å¤§å°
- `gradient_accumulation_steps`: æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
- `warmup_ratio`: é¢„çƒ­æ¯”ä¾‹
- `weight_decay`: æƒé‡è¡°å‡
- `max_grad_norm`: æ¢¯åº¦è£å‰ªé˜ˆå€¼

### æ•ˆç‡ä¼˜åŒ–é…ç½®
- `use_muon_optimizer`: æ˜¯å¦ä½¿ç”¨ Muon ä¼˜åŒ–å™¨
- `use_flash_attention`: æ˜¯å¦ä½¿ç”¨ Flash Attention
- `use_gradient_checkpointing`: æ˜¯å¦ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
- `use_bf16`: æ˜¯å¦ä½¿ç”¨ bfloat16 ç²¾åº¦
- `dataloader_num_workers`: æ•°æ®åŠ è½½è¿›ç¨‹æ•°

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. ç¡¬ä»¶è¦æ±‚
- **GPU**: å»ºè®®ä½¿ç”¨ 24GB+ æ˜¾å­˜çš„ GPU (å¦‚ A100, RTX 4090)
- **å†…å­˜**: å»ºè®® 32GB+ ç³»ç»Ÿå†…å­˜
- **å­˜å‚¨**: è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´å­˜å‚¨æ¨¡å‹å’Œæ£€æŸ¥ç‚¹

### 2. è¶…å‚æ•°è°ƒä¼˜
```python
# æ ¹æ®æ¨¡å‹è§„æ¨¡è°ƒæ•´å­¦ä¹ ç‡
# å­¦ä¹ ç‡ âˆ N^(-0.25)ï¼Œå…¶ä¸­ N æ˜¯æ¨¡å‹å‚æ•°é‡
if model_size == "7B":
    learning_rate = 5e-5
elif model_size == "14B":
    learning_rate = 3e-5
elif model_size == "32B":
    learning_rate = 2e-5

# æ ¹æ®æ•°æ®è§„æ¨¡è°ƒæ•´æ‰¹é‡å¤§å°
# æ‰¹é‡å¤§å° âˆ (N * D)^0.4ï¼Œå…¶ä¸­ N æ˜¯å‚æ•°é‡ï¼ŒD æ˜¯æ•°æ®é‡
effective_batch_size = (model_params * data_size) ** 0.4
```

### 3. å†…å­˜ä¼˜åŒ–
```python
# å¯ç”¨æ‰€æœ‰å†…å­˜ä¼˜åŒ–é€‰é¡¹
config = CPTConfig(
    use_gradient_checkpointing=True,  # èŠ‚çœæ˜¾å­˜
    use_bf16=True,  # æ··åˆç²¾åº¦
    per_device_train_batch_size=1,  # å°æ‰¹é‡
    gradient_accumulation_steps=16,  # é€šè¿‡ç´¯ç§¯å®ç°å¤§æ‰¹é‡
)
```

## ç›‘æ§å’Œè°ƒè¯•

### 1. æ—¥å¿—ç›‘æ§
è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè¾“å‡ºè¯¦ç»†çš„æ—¥å¿—ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
- æ¯ä¸ªæ­¥éª¤çš„æŸå¤±å€¼
- å¹³å‡æŸå¤±
- å­¦ä¹ ç‡å˜åŒ–
- å†…å­˜ä½¿ç”¨æƒ…å†µ

### 2. æ¨¡å‹ä¿å­˜
- æ¯ä¸ª epoch åä¿å­˜æ£€æŸ¥ç‚¹
- æœ€ä½³æ¨¡å‹è‡ªåŠ¨ä¿å­˜
- æœ€ç»ˆæ¨¡å‹ä¿å­˜
- é…ç½®æ–‡ä»¶ä¿å­˜

### 3. å¸¸è§é—®é¢˜
1. **æ˜¾å­˜ä¸è¶³**: å‡å°‘æ‰¹é‡å¤§å°ï¼Œå¢åŠ æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
2. **è®­ç»ƒé€Ÿåº¦æ…¢**: ç¡®ä¿å¯ç”¨äº† Flash Attention å’Œ Muon ä¼˜åŒ–å™¨
3. **æ”¶æ•›æ…¢**: è°ƒæ•´å­¦ä¹ ç‡å’Œé¢„çƒ­æ¯”ä¾‹

## å®éªŒè·Ÿè¸ª

å¯ä»¥ä½¿ç”¨ Weights & Biases æˆ– TensorBoard è¿›è¡Œå®éªŒè·Ÿè¸ªï¼š

```python
# åœ¨é…ç½®ä¸­æ·»åŠ 
config.wandb_project = "qwen2.5-cpt"
config.logging_dir = "./logs"
```

## æœ€ä½³å®è·µ

1. **æ•°æ®è´¨é‡**: ç¡®ä¿è®­ç»ƒæ•°æ®çš„é«˜è´¨é‡å’Œå¤šæ ·æ€§
2. **æ¸è¿›å¼è®­ç»ƒ**: å…ˆåœ¨å°æ•°æ®é›†ä¸Šæµ‹è¯•ï¼Œå†æ‰©å±•åˆ°å¤§è§„æ¨¡æ•°æ®
3. **å®šæœŸè¯„ä¼°**: ä½¿ç”¨éªŒè¯é›†ç›‘æ§æ¨¡å‹æ€§èƒ½
4. **æ£€æŸ¥ç‚¹ç®¡ç†**: å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹ï¼Œé¿å…è®­ç»ƒä¸­æ–­
5. **èµ„æºç›‘æ§**: ç›‘æ§ GPU å’Œå†…å­˜ä½¿ç”¨æƒ…å†µ

## æ€§èƒ½åŸºå‡†

åœ¨æ ‡å‡†ç¡¬ä»¶é…ç½®ä¸‹çš„é¢„æœŸæ€§èƒ½ï¼š

| æ¨¡å‹è§„æ¨¡ | GPU | æ‰¹é‡å¤§å° | è®­ç»ƒé€Ÿåº¦ | æ˜¾å­˜ä½¿ç”¨ |
|---------|-----|---------|---------|---------|
| 7B      | A100 40GB | 4 | ~100 tokens/s | ~35GB |
| 14B     | A100 40GB | 2 | ~60 tokens/s | ~38GB |
| 32B     | A100 80GB | 1 | ~30 tokens/s | ~70GB |

*æ³¨ï¼šå®é™…æ€§èƒ½å¯èƒ½å› ç¡¬ä»¶é…ç½®å’Œæ•°æ®ç‰¹å¾è€Œæœ‰æ‰€ä¸åŒ*
